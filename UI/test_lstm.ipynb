{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 확인 및 인덱스 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>UserID</th>\n",
       "      <th>products</th>\n",
       "      <th>Categories of the products</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>time</th>\n",
       "      <th>content of review</th>\n",
       "      <th>userid:helpfulness voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392</td>\n",
       "      <td>5247778.0</td>\n",
       "      <td>Mary Poppins (DVD)</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>50.0</td>\n",
       "      <td>very helpful</td>\n",
       "      <td>22.08.2004</td>\n",
       "      <td>In 1964 I was 10, a village girl who rarel...</td>\n",
       "      <td>6224941:3, 5309969:3, 5309969:3, 5270615:3, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1663</td>\n",
       "      <td>5647565.0</td>\n",
       "      <td>The Box (DVD)</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>very helpful</td>\n",
       "      <td>06.11.2010</td>\n",
       "      <td>Norma and Arthur Lewis are an ordinary mid...</td>\n",
       "      <td>5719918:4, 6690494:4, 6690494:4, 5466331:4, 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1664</td>\n",
       "      <td>5647565.0</td>\n",
       "      <td>Doomed To Die (DVD)</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>very helpful</td>\n",
       "      <td>30.10.2010</td>\n",
       "      <td>Shipping magnate Cyrus Wentworth is devast...</td>\n",
       "      <td>5552133:4, 5552133:4, 5719918:4, 5633146:4, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1665</td>\n",
       "      <td>5647565.0</td>\n",
       "      <td>Haunting The (DVD)</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>50.0</td>\n",
       "      <td>very helpful</td>\n",
       "      <td>29.10.2010</td>\n",
       "      <td>Hill House has a ghostly past, full of vio...</td>\n",
       "      <td>5719918:4, 5633146:4, 5534578:4, 6023030:4, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1666</td>\n",
       "      <td>5647565.0</td>\n",
       "      <td>The Invisible Ghost (DVD)</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>very helpful</td>\n",
       "      <td>27.10.2010</td>\n",
       "      <td>Dr Charles Kessler is a mild-mannered man ...</td>\n",
       "      <td>5719918:4, 5633146:4, 6023030:4, 6023030:4, 55...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     UserID                   products Categories of the products  \\\n",
       "0   1392  5247778.0         Mary Poppins (DVD)                       DVDs   \n",
       "1   1663  5647565.0              The Box (DVD)                       DVDs   \n",
       "2   1664  5647565.0        Doomed To Die (DVD)                       DVDs   \n",
       "3   1665  5647565.0         Haunting The (DVD)                       DVDs   \n",
       "4   1666  5647565.0  The Invisible Ghost (DVD)                       DVDs   \n",
       "\n",
       "   rating   helpfulness        time  \\\n",
       "0    50.0  very helpful  22.08.2004   \n",
       "1    30.0  very helpful  06.11.2010   \n",
       "2    30.0  very helpful  30.10.2010   \n",
       "3    50.0  very helpful  29.10.2010   \n",
       "4    30.0  very helpful  27.10.2010   \n",
       "\n",
       "                                   content of review  \\\n",
       "0      In 1964 I was 10, a village girl who rarel...   \n",
       "1      Norma and Arthur Lewis are an ordinary mid...   \n",
       "2      Shipping magnate Cyrus Wentworth is devast...   \n",
       "3      Hill House has a ghostly past, full of vio...   \n",
       "4      Dr Charles Kessler is a mild-mannered man ...   \n",
       "\n",
       "                           userid:helpfulness voting  \n",
       "0  6224941:3, 5309969:3, 5309969:3, 5270615:3, 55...  \n",
       "1  5719918:4, 6690494:4, 6690494:4, 5466331:4, 54...  \n",
       "2  5552133:4, 5552133:4, 5719918:4, 5633146:4, 55...  \n",
       "3  5719918:4, 5633146:4, 5534578:4, 6023030:4, 60...  \n",
       "4  5719918:4, 5633146:4, 6023030:4, 6023030:4, 55...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_feather(\"../dataset/rating_groupby_category_feather/rating_DVDs.feather\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_feather(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/rating_groupby_category_feather/rating_DVDs.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# 첫 번째 'embedding'의 차원\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimension:\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_dim)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# null byte 제거 및 개수 추적\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embedding_dim = df['embedding'].iloc[0].shape  # 첫 번째 'embedding'의 차원\n",
    "print(\"Embedding dimension:\", embedding_dim)\n",
    "\n",
    "# null byte 제거 및 개수 추적\n",
    "def remove_null_bytes(x):\n",
    "    # x는 numpy array로, 각 요소에 대해 null byte(\\x00)의 개수를 셈\n",
    "    null_byte_count = np.char.count(x.astype(str), '\\x00').sum()  # null byte의 개수 세기\n",
    "    cleaned_x = np.array([i.replace('\\x00', '') for i in x.astype(str)])  # null byte를 제거한 배열\n",
    "    return cleaned_x, null_byte_count\n",
    "\n",
    "# 데이터프레임에 적용\n",
    "df['embedding'], df['null_byte_count'] = zip(*df['embedding'].apply(lambda x: remove_null_bytes(x)))\n",
    "\n",
    "# 결과 확인\n",
    "print(df[['embedding', 'null_byte_count']].head())\n",
    "\n",
    "df.sample(6)\n",
    "\n",
    "# 첫 번째 embedding 벡터의 차원 출력\n",
    "embedding_dim = df['embedding'].iloc[0].shape  # 첫 번째 'embedding'의 차원\n",
    "print(\"Embedding dimension:\", embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec로 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content of review'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content of review'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 문장을 토큰화하고 review_idx를 태그로 지정\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tagged_data \u001b[38;5;241m=\u001b[39m [TaggedDocument(words\u001b[38;5;241m=\u001b[39mword_tokenize(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent of review\u001b[39m\u001b[38;5;124m'\u001b[39m]), tags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# doc2vec 모델 학습\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(tagged_data, vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 문장을 토큰화하고 review_idx를 태그로 지정\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tagged_data \u001b[38;5;241m=\u001b[39m [TaggedDocument(words\u001b[38;5;241m=\u001b[39mword_tokenize(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent of review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m), tags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# doc2vec 모델 학습\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(tagged_data, vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/duu/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content of review'"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# 문장을 토큰화하고 review_idx를 태그로 지정\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(row['content of review']), tags=[str(row['index'])]) for _, row in df.iterrows()]\n",
    "\n",
    "# doc2vec 모델 학습\n",
    "model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "\n",
    "# 각 리뷰의 벡터를 가져오기\n",
    "df['embedding'] = df['index'].apply(lambda idx: model.dv[str(idx)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['UserID'] = df['UserID'].astype(str)\n",
    "df['UserID'] = df['UserID'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "# 날짜 변환 (DD.MM.YYYY → timestamp)\n",
    "df['time'] = pd.to_datetime(df['time'], format='%d.%m.%Y')\n",
    "df['time'] = df['time'].astype('int64') // 10**9  # 초 단위로 변환\n",
    "\n",
    "final_df = df[['userid', 'time', 'embedding']]\n",
    "final_df.to_feather(\"../dataset/test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lstm 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.7560\n",
      "Epoch 2, Loss: 2.8489\n",
      "Epoch 3, Loss: 1.7420\n",
      "Epoch 4, Loss: 1.3038\n",
      "Epoch 5, Loss: 1.1692\n",
      "Epoch 6, Loss: 1.1045\n",
      "Epoch 7, Loss: 1.0144\n",
      "Epoch 8, Loss: 0.8410\n",
      "Epoch 9, Loss: 0.6278\n",
      "Epoch 10, Loss: 0.5099\n",
      "Predicted preferences saved to 'predicted_user_preferences.feather'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_feather(\"../dataset/rating_for_UI_feather/rating_Adult Products.feather\")\n",
    "\n",
    "# 리스트 형태의 embedding을 실제 리스트로 변환\n",
    "# null byte 제거하기\n",
    "df['embedding'] = df['embedding'].apply(\n",
    "    lambda x: np.array(eval(x.replace('\\x00', ''))) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# UserID와 time을 기준으로 정렬\n",
    "df = df.sort_values(by=['UserID', 'time'])\n",
    "\n",
    "user_sequences = []\n",
    "user_targets = []\n",
    "\n",
    "for user_id, group in df.groupby('UserID'):\n",
    "    sequence = np.stack(group['embedding'].values)  # embedding 벡터 리스트 → 배열 변환\n",
    "    if len(sequence) > 1:  # 최소한 2개 이상의 데이터가 있어야 시퀀스를 만들 수 있음\n",
    "        user_sequences.append(sequence[:-1])  # 입력 시퀀스\n",
    "        user_targets.append(sequence[1:])  # 타겟 (다음 시간의 선호 벡터)\n",
    "\n",
    "class LSTMPreferenceModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LSTMPreferenceModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, embedding_dim)  # LSTM 출력 → 선호 벡터 예측\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "embedding_dim = 100  # 벡터 차원\n",
    "hidden_dim = 128  # LSTM 은닉층 차원\n",
    "num_layers = 2  # LSTM 레이어 개수\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMPreferenceModel(embedding_dim, hidden_dim, num_layers)\n",
    "criterion = nn.MSELoss()  # 예측된 벡터와 실제 벡터 간 차이를 최소화\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for seq, target in zip(user_sequences, user_targets):\n",
    "        seq_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)  # (1, 시퀀스 길이, 100)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.float32).unsqueeze(0)  # (1, 시퀀스 길이, 100)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(seq_tensor)\n",
    "        loss = criterion(output, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "def predict_future_preference(user_id, past_embeddings):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        seq_tensor = torch.tensor(past_embeddings, dtype=torch.float32).unsqueeze(0)\n",
    "        predicted_future = model(seq_tensor)\n",
    "    return predicted_future.squeeze(0).numpy()\n",
    "\n",
    "# 각 유저에 대한 선호 벡터 예측\n",
    "user_predictions = {}\n",
    "for user_id, user_sequence in zip(df['UserID'].unique(), user_sequences):\n",
    "    past_embeddings = user_sequence[-5:]  # 최근 5개 embedding 사용\n",
    "    predicted_preference = predict_future_preference(user_id, past_embeddings)\n",
    "    user_predictions[user_id] = predicted_preference[-1]  # 마지막 예측 벡터 (미래 선호 벡터)\n",
    "\n",
    "# 유저별 예측된 선호 벡터를 DataFrame으로 변환\n",
    "user_predictions_df = pd.DataFrame(\n",
    "    [(user_id, predicted_pref) for user_id, predicted_pref in user_predictions.items()],\n",
    "    columns=['UserID', 'Predicted Preference']\n",
    ")\n",
    "\n",
    "# 예측 결과를 Feather 형식으로 저장\n",
    "user_predictions_df.to_feather(\"../dataset/predicted_user_preferences.feather\")\n",
    "\n",
    "print(\"Predicted preferences saved to 'predicted_user_preferences.feather'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Predicted Preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11996</td>\n",
       "      <td>[-0.4516291, 0.15521911, -1.0964531, 0.1853739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2815</td>\n",
       "      <td>[-0.3822423, 0.32363, -1.0623038, 0.4568331, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5001156</td>\n",
       "      <td>[-0.4474397, 0.25937295, -1.1561599, 0.3420246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5002475</td>\n",
       "      <td>[-0.46374485, 0.10646514, -1.0883391, 0.217411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5016738</td>\n",
       "      <td>[-0.39016166, 0.431353, -1.1600732, 0.5669898,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserID                               Predicted Preference\n",
       "0    11996  [-0.4516291, 0.15521911, -1.0964531, 0.1853739...\n",
       "1     2815  [-0.3822423, 0.32363, -1.0623038, 0.4568331, 0...\n",
       "2  5001156  [-0.4474397, 0.25937295, -1.1561599, 0.3420246...\n",
       "3  5002475  [-0.46374485, 0.10646514, -1.0883391, 0.217411...\n",
       "4  5016738  [-0.39016166, 0.431353, -1.1600732, 0.5669898,..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(\"../output/UI_output/rating_Adult Products_UI.feather\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duu",
   "language": "python",
   "name": "duu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
